{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first NLP exercise is about preprocessing.\n",
    "\n",
    "You will practice preprocessing using NLTK on raw data. \n",
    "This is the first step in most of the NLP projects, so you have to master it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will play with the *coldplay.csv* dataset, containing all the songs and lyrics of Coldplay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jpo-0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jpo-0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jpo-0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jpo-0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "nltk.download('punkt') #Run this line one time to get the resource\n",
    "nltk.download('stopwords') #Run this line one time to get the resource\n",
    "nltk.download('wordnet') #Run this line one time to get the resource\n",
    "nltk.download('averaged_perceptron_tagger') #Run this line one time to get the resource\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Link</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Another's Arms</td>\n",
       "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
       "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Bigger Stronger</td>\n",
       "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
       "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>/c/coldplay/daylight_20032625.html</td>\n",
       "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Everglow</td>\n",
       "      <td>/c/coldplay/everglow_21104546.html</td>\n",
       "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Every Teardrop Is A Waterfall</td>\n",
       "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
       "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Artist                           Song  \\\n",
       "0  Coldplay                 Another's Arms   \n",
       "1  Coldplay                Bigger Stronger   \n",
       "2  Coldplay                       Daylight   \n",
       "3  Coldplay                       Everglow   \n",
       "4  Coldplay  Every Teardrop Is A Waterfall   \n",
       "\n",
       "                                                Link  \\\n",
       "0            /c/coldplay/anothers+arms_21079526.html   \n",
       "1          /c/coldplay/bigger+stronger_20032648.html   \n",
       "2                 /c/coldplay/daylight_20032625.html   \n",
       "3                 /c/coldplay/everglow_21104546.html   \n",
       "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  Late night watching tv  \\nUsed to be you here ...  \n",
       "1  I want to be bigger stronger drive a faster ca...  \n",
       "2  To my surprise, and my delight  \\nI saw sunris...  \n",
       "3  Oh, they say people come  \\nThey say people go...  \n",
       "4  I turn the music up, I got my records on  \\nI ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv('coldplay.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the dataset, play with it a bit: what are the columns? How many lines? Is there missing data?..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Artist  120 non-null    object\n",
      " 1   Song    120 non-null    object\n",
      " 2   Link    120 non-null    object\n",
      " 3   Lyrics  120 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the song 'Every Teardrop Is A Waterfall' and save the Lyrics text into a variable. Print the output of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    I turn the music up, I got my records on  \\nI ...\n",
       "Name: Lyrics, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Select the song 'Every Teardrop Is A Waterfall'\n",
    "song = df[df['Song'] == \"Every Teardrop Is A Waterfall\"][\"Lyrics\"]\n",
    "song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is some preprocessing needed here. So let's do it! What is usually the first step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, yes. So do tokenization on the lyrics of Every Teardrop Is A Waterfall.\n",
    "\n",
    "So you may have to import the needed library from NLTK if you did not yet.\n",
    "\n",
    "Be careful, the output you have from your pandas dataframe may not have the right type, so manipulate it wisely to get a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " ',',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " ',',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " ',',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " ',',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " \"'ll\",\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Tokenize the lyrics of the song and save the tokens into a variable and print it\n",
    "# Natural language tool kit has a function called word_tokenize, can get the tokens by passing in the df values index 0\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(song.values[0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It begins to look good. But still, we have the punctuation to remove, so let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'I',\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'it',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Remove the punctuation, then save the result into a variable and print it\n",
    "# Can remove the punctuation by checking if characters are alphabet letters only\n",
    "tokens = [t for t in tokens if t.isalpha()]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'records',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'streets',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'trees',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'kids',\n",
       " 'dance',\n",
       " 'kids',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'records',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'I',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'soar',\n",
       " 'walls',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove the stop words using NLTK. Then put the result into a variable and print it\n",
    "from nltk.corpus import stopwords\n",
    "# See nltk documentation for stopwords usage if needed\n",
    "stop_words = stopwords.words('english')\n",
    "# This is just a list of english stop words, nothing else\n",
    "tokens_no_stops = [t for t in tokens if t not in stop_words]\n",
    "# Use basic Python again to make a listen that only keeps non-stopwords\n",
    "tokens_no_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we begin to have much less words in our song, right?\n",
    "\n",
    "Next step is lemmatization. But we had an issue in the lectures, you remember? Let's learn how to do it properly now.\n",
    "\n",
    "First let's try to do it naively. Import the WordNetLemmatizer and perform lemmatization with default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'record',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'light',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'street',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'tree',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'kid',\n",
       " 'dance',\n",
       " 'kid',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feel',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'record',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'I',\n",
       " 'knee',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapeze',\n",
       " 'But',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulse',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'soar',\n",
       " 'wall',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform lemmatization using WordNetLemmatizer on our tokens\n",
    "# lemmatization is an alternative to stemming, but retaining real words not breaking them down fully. eg. records > record\n",
    "# Once again use the documentation\n",
    "# In this case the code for the library is written in the way that we initiate the lemmatizer as an object\n",
    "# We then use a method of the object to lemmatize the words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "lem_tokens = [lemma.lemmatize(t) for t in tokens_no_stops]\n",
    "lem_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it worked well on nouns (plural words are now singular for example).\n",
    "\n",
    "But verbs are not OK: we would 'is' to become 'be' for example.\n",
    "\n",
    "To do that, we need to do POS-tagging. So let's do this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS-tagging means Part of speech tagging: basically it will classify words into categories: like verbs, nouns, advers and so on...\n",
    "\n",
    "In order to do that, we will use NLTK and the function *pos_tag*. You have to do it on the step before lemmatization, so use your variable containing all the tokens without punctuation and without stop words.\n",
    "\n",
    "Hint: you can check on the internet how the *pos_tag* function works [here](https://www.nltk.org/book/ch05.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('records', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('shut', 'VBP'),\n",
       " ('world', 'NN'),\n",
       " ('outside', 'IN'),\n",
       " ('lights', 'NNS'),\n",
       " ('come', 'VBP'),\n",
       " ('Maybe', 'RB'),\n",
       " ('streets', 'NNS'),\n",
       " ('alight', 'VBD'),\n",
       " ('maybe', 'RB'),\n",
       " ('trees', 'VBZ'),\n",
       " ('gone', 'VBN'),\n",
       " ('I', 'PRP'),\n",
       " ('feel', 'VBP'),\n",
       " ('heart', 'NN'),\n",
       " ('start', 'NN'),\n",
       " ('beating', 'VBG'),\n",
       " ('favourite', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('kids', 'NNS'),\n",
       " ('dance', 'NN'),\n",
       " ('kids', 'NNS'),\n",
       " ('night', 'NN'),\n",
       " ('Until', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('morning', 'NN'),\n",
       " ('feels', 'NNS'),\n",
       " ('another', 'DT'),\n",
       " ('life', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('roll', 'VBP'),\n",
       " ('time', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('heaven', 'JJ'),\n",
       " ('sight', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('records', 'NNS'),\n",
       " ('From', 'IN'),\n",
       " ('underneath', 'JJ'),\n",
       " ('rubble', 'JJ'),\n",
       " ('sing', 'VBG'),\n",
       " ('rebel', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('Do', 'NNP'),\n",
       " ('want', 'VB'),\n",
       " ('see', 'VB'),\n",
       " ('another', 'DT'),\n",
       " ('generation', 'NN'),\n",
       " ('drop', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('rather', 'RB'),\n",
       " ('comma', 'VBP'),\n",
       " ('full', 'JJ'),\n",
       " ('stop', 'NN'),\n",
       " ('Maybe', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('black', 'JJ'),\n",
       " ('maybe', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('knees', 'VBP'),\n",
       " ('Maybe', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('gap', 'VBP'),\n",
       " ('two', 'CD'),\n",
       " ('trapezes', 'NNS'),\n",
       " ('But', 'CC'),\n",
       " ('heart', 'NN'),\n",
       " ('beating', 'NN'),\n",
       " ('pulses', 'NNS'),\n",
       " ('start', 'VBP'),\n",
       " ('Cathedrals', 'NNP'),\n",
       " ('heart', 'NN'),\n",
       " ('As', 'IN'),\n",
       " ('saw', 'JJ'),\n",
       " ('oh', 'IN'),\n",
       " ('light', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('swear', 'VBP'),\n",
       " ('emerge', 'RB'),\n",
       " ('blinking', 'VBG'),\n",
       " ('To', 'TO'),\n",
       " ('tell', 'VB'),\n",
       " ('alright', 'RB'),\n",
       " ('As', 'IN'),\n",
       " ('soar', 'NN'),\n",
       " ('walls', 'NNS'),\n",
       " ('every', 'DT'),\n",
       " ('siren', 'NN'),\n",
       " ('symphony', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('tear', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Is', 'VBZ'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('Is', 'NNP'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('oh', 'MD'),\n",
       " ('oh', 'VB'),\n",
       " ('Is', 'NNP'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Is', 'VBZ'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('oh', 'MD'),\n",
       " ('oh', 'VB'),\n",
       " ('So', 'NNP'),\n",
       " ('hurt', 'JJ'),\n",
       " ('hurt', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('But', 'CC'),\n",
       " ('still', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('raise', 'VBP'),\n",
       " ('flag', 'JJ'),\n",
       " ('Oh', 'IN'),\n",
       " ('It', 'PRP'),\n",
       " ('wa', 'VBZ'),\n",
       " ('wa', 'JJ'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'VBD'),\n",
       " ('A', 'NNP'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use the function pos_tag of NLTK to perform POS-tagging and print the result\n",
    "# We pass in the non-lemmatized words first so we can do the part of speech tagging, then we will lemmatize\n",
    "tags = nltk.pos_tag(tokens_no_stops)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it does not return values like 'a', 'n', 'v' or 'r' as the WordNet lemmatizer is expecting...\n",
    "\n",
    "So we have to convert the values from the NLTK POS-tagging to put them into the WordNet Lemmatizer. This is done in the function *get_wordnet_pos* written below. Try to understand it, and then we will reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below function simply assesses what type of word based on the previous tagged and changes it to the WordNet representation\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    output = np.asarray(pos_tag)\n",
    "    for i in range(len(pos_tag)):\n",
    "        if pos_tag[i][1].startswith('J'):\n",
    "            output[i][1] = wordnet.ADJ\n",
    "        elif pos_tag[i][1].startswith('V'):\n",
    "            output[i][1] = wordnet.VERB\n",
    "        elif pos_tag[i][1].startswith('R'):\n",
    "            output[i][1] = wordnet.ADV\n",
    "        else:\n",
    "            output[i][1] = wordnet.NOUN\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you have all we need to perform properly the lemmatization.\n",
    "\n",
    "So you have to use the following to do so:\n",
    "* your tags from the POS-tagging performed\n",
    "* the function *get_wordnet_pos*\n",
    "* the *WordNetLemmatizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'get',\n",
       " 'record',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'light',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'street',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beat',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'kid',\n",
       " 'dance',\n",
       " 'kid',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feel',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'get',\n",
       " 'record',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'I',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapeze',\n",
       " 'But',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulse',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blink',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'soar',\n",
       " 'wall',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform the lemmatization properly\n",
    "wordnet_input = get_wordnet_pos(tags)\n",
    "# If you print this you will see it has converted the tags to wordnet representations\n",
    "# See documentation for the two parameters within the lemmatize function\n",
    "# The first parameter is the word I believe and the second is the tag type, it just got this from the wordnet_input var\n",
    "lem_tokens_complete = [lemma.lemmatize(t, tag) for t,tag in wordnet_input]\n",
    "lem_tokens_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think?\n",
    "\n",
    "Still not perfect, but it's the best we can do for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try stemming, with the help of the lecture, and see the differences compared to the lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'turn', 'music', 'I', 'got', 'record', 'I', 'shut', 'world', 'outsid', 'light', 'come', 'mayb', 'street', 'alight', 'mayb', 'tree', 'gone', 'I', 'feel', 'heart', 'start', 'beat', 'favourit', 'song', 'and', 'kid', 'danc', 'kid', 'night', 'until', 'monday', 'morn', 'feel', 'anoth', 'life', 'I', 'turn', 'music', 'I', 'roll', 'time', 'and', 'heaven', 'sight', 'I', 'turn', 'music', 'I', 'got', 'record', 'from', 'underneath', 'rubbl', 'sing', 'rebel', 'song', 'Do', 'want', 'see', 'anoth', 'gener', 'drop', 'I', 'rather', 'comma', 'full', 'stop', 'mayb', 'I', 'black', 'mayb', 'I', 'knee', 'mayb', 'I', 'gap', 'two', 'trapez', 'but', 'heart', 'beat', 'puls', 'start', 'cathedr', 'heart', 'As', 'saw', 'oh', 'light', 'I', 'swear', 'emerg', 'blink', 'To', 'tell', 'alright', 'As', 'soar', 'wall', 'everi', 'siren', 'symphoni', 'and', 'everi', 'tear', 'waterfal', 'Is', 'waterfal', 'Oh', 'Is', 'waterfal', 'Oh', 'oh', 'oh', 'Is', 'waterfal', 'everi', 'tear', 'Is', 'waterfal', 'Oh', 'oh', 'oh', 'So', 'hurt', 'hurt', 'bad', 'but', 'still', 'I', 'rais', 'flag', 'Oh', 'It', 'wa', 'wa', 'wa', 'wa', 'A', 'wa', 'wa', 'wa', 'wa', 'everi', 'tear', 'everi', 'tear', 'everi', 'teardrop', 'waterfal', 'everi', 'tear', 'everi', 'tear', 'everi', 'teardrop', 'waterfal', 'everi', 'tear', 'everi', 'tear', 'everi', 'teardrop', 'waterfal']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Perform stemming\n",
    "# Stemming is different to lemmatization\n",
    "from nltk.stem import PorterStemmer\n",
    "# LOOK AT THE DOCUMENTATION FOR ANY FUNCTIONS USED\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(t) for t in tokens_no_stops]\n",
    "print(stemmed_tokens)\n",
    "# Should also be able to convert all to lowercase using the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the difference? What would you use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
